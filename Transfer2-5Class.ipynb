{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "==>>> epoch: 0, train loss: 0.279388, acc: 0.411, f1:0.963\n",
      "==>>> epoch: 0, test loss: 9.190199, acc: 0.114, f1:0.711\n",
      "==>>> epoch: 1, train loss: 0.368205, acc: 0.357, f1:0.886\n",
      "==>>> epoch: 1, test loss: 7.905378, acc: 0.114, f1:0.711\n",
      "==>>> epoch: 2, train loss: 0.304794, acc: 0.362, f1:0.896\n",
      "==>>> epoch: 2, test loss: 7.633440, acc: 0.114, f1:0.711\n",
      "==>>> epoch: 3, train loss: 0.278067, acc: 0.362, f1:0.899\n",
      "==>>> epoch: 3, test loss: 7.576861, acc: 0.114, f1:0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-72:\n",
      "Process Process-70:\n",
      "Process Process-69:\n",
      "Process Process-71:\n",
      "Process Process-68:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-66:\n",
      "Process Process-67:\n",
      "Process Process-65:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib64/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 143, in __call__\n",
      "    return F.normalize(tensor, self.mean, self.std)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/lib64/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 168, in normalize\n",
      "    t.sub_(m).div_(s)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib64/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib64/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib64/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib64/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-52a1f375399a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mtotal_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "#import bcolz\n",
    "import time\n",
    "from utils import *\n",
    "cwd = os.getcwd()\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "prep1 = transforms.Compose([\n",
    "            #transforms.RandomSizedCrop(512),\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "\n",
    "data_dir = 'Samples/'\n",
    "\n",
    "class Dataset():\n",
    "    __xs = []\n",
    "    __ys = []\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.transform = transform\n",
    "        # Open and load text file including the whole training data\n",
    "        with open(folder_dataset + \"data.txt\") as f:\n",
    "            for line in f:\n",
    "                # Image path\n",
    "                self.__xs.append(path + line.split()[0])        \n",
    "                # Steering wheel label\n",
    "                self.__ys.append(np.float32(line.split()[1]))\n",
    "\n",
    "    # Override to give PyTorch access to any image on the dataset\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.__xs[index])\n",
    "        #img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Convert image and label to torch tensors\n",
    "        img = torch.from_numpy(np.asarray(img))\n",
    "        label = torch.from_numpy(np.asarray(self.__ys[index]).reshape([1,1]))\n",
    "        return img, label\n",
    "\n",
    "    # Override to give PyTorch size of dataset\n",
    "    def __len__(self):\n",
    "        return len(self.__xs)\n",
    "\n",
    "\n",
    "transformer = transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5,),(1.0,))])\n",
    "\n",
    "\n",
    "train = torchvision.datasets.ImageFolder(cwd + '/Samples2/train',transform=transformer)\n",
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                          batch_size=48,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=8)\n",
    "\n",
    "test = torchvision.datasets.ImageFolder(cwd + '/Samples2/test',transform=transformer)\n",
    "test_loader = torch.utils.data.DataLoader(test,\n",
    "                                          batch_size=48,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=8)    \n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "#model_conv = models.alexnet(pretrained=True)\n",
    "#model_conv = models.squeezenet1_0(pretrained=True)\n",
    "#model_conv = models.vgg16(pretrained=True)\n",
    "#model_conv = models.densenet161(pretrained=True)\n",
    "#model_conv = models.inception_v3(pretrained=True)\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "print(num_ftrs)\n",
    "model_conv.fc = nn.Linear(num_ftrs* 100, 1024)\n",
    "model_conv.fc2 = nn.Linear(1024, 5)\n",
    "model= model_conv.to(device)\n",
    "#print(model)\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(1)\n",
    "torch.backends.cudnn.benchmark=True\n",
    "torch.backends.cudnn.fastest = True\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loss = []\n",
    "train_f1 = []\n",
    "test_loss = []\n",
    "test_f1 = []\n",
    "for epoch in range(20):\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    image = 0\n",
    "    count = 0\n",
    "    batch = 0\n",
    "    TP = 0 #true positive\n",
    "    FP = 0 #false positive\n",
    "    FN = 0 #false negative\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        if x.shape[0] != 48:\n",
    "            break\n",
    "        for i in range(x.shape[0]):\n",
    "            if count == 0:\n",
    "                image = x[i,2:,:,:]\n",
    "                count += 1\n",
    "                continue\n",
    "            elif count == 1:\n",
    "                image = torch.cat((image, x[i,2:,:,:]), dim=0)\n",
    "                count += 1\n",
    "                continue\n",
    "            else:\n",
    "                image = torch.cat((image, x[i,2:,:,:]), dim=0)\n",
    "                count = 0\n",
    "            if i == 2:\n",
    "                batch = image.reshape((-1,3,512,512))\n",
    "            else:\n",
    "                batch = torch.cat((batch, image.reshape((1,3,512,512))), dim=0)\n",
    "                #print(batch.shape)\n",
    "        tar = []\n",
    "        for i in range(target.shape[0]):\n",
    "            if i % 3 == 0:\n",
    "                tar.append(target[i].item())\n",
    "        target = torch.LongTensor(tar)\n",
    "        x = batch.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target.cuda())\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.shape[0]\n",
    "        correct_cnt+= (pred_label == target.cuda()).sum().item()\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for indx in range(16):\n",
    "            \n",
    "            if target[indx].item() > 0.5:\n",
    "                if pred_label[indx].item() > 0.5:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "            else:\n",
    "                if pred_label[indx].item() > 0.5:\n",
    "                    FP += 1\n",
    "\n",
    "            total_cnt += 1\n",
    "                    \n",
    "        if TP == 0 and FP == 0:\n",
    "            FP = 1\n",
    "        if TP == 0 and FN == 0:\n",
    "            FN = 1\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        if precision == 0 and recall == 0:\n",
    "            recall = 1\n",
    "        f1 = 2*((precision*recall)/(precision+recall))\n",
    "    train_loss.append(ave_loss)\n",
    "    train_f1.append(f1)\n",
    "    print('==>>> epoch: {}, train loss: {:.6f}, acc: {:.3f}, f1:{:.3f}'.format(\n",
    "                epoch, ave_loss, correct_cnt*1.0/total_cnt, f1))\n",
    "    # testing\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    image = 0\n",
    "    count = 0\n",
    "    batch = 0\n",
    "    TP = 0 #true positive\n",
    "    FP = 0 #false positive\n",
    "    FN = 0 #false negative\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        if x.shape[0] != 48:\n",
    "            break\n",
    "        for i in range(x.shape[0]):\n",
    "            if count == 0:\n",
    "                image = x[i,2:,:,:]\n",
    "                count += 1\n",
    "                continue\n",
    "            elif count == 1:\n",
    "                image = torch.cat((image, x[i,2:,:,:]), dim=0)\n",
    "                count += 1\n",
    "                continue\n",
    "            else:\n",
    "                image = torch.cat((image, x[i,2:,:,:]), dim=0)\n",
    "                count = 0\n",
    "            if i == 2:\n",
    "                batch = image.reshape((-1,3,512,512))\n",
    "            else:\n",
    "                batch = torch.cat((batch, image.reshape((1,3,512,512))), dim=0)\n",
    "                #print(batch.shape)\n",
    "        x = batch.cuda()\n",
    "        \n",
    "        tar = []\n",
    "        for i in range(target.shape[0]):\n",
    "            if i % 3 == 0:\n",
    "                tar.append(target[i].item())\n",
    "        target = torch.LongTensor(tar)\n",
    "        #print(target.shape)\n",
    "        out = model(x)\n",
    "        #print(out.shape)\n",
    "        loss = criterion(out, target.cuda())\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.shape[0]\n",
    "#         print(target.data)\n",
    "        correct_cnt += (pred_label == target.cuda()).sum().item()\n",
    "        # smooth average\n",
    "        ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "        for indx in range(16):\n",
    "            \n",
    "            if target[indx].item() > 0.5:\n",
    "                if pred_label[indx].item() > 0.5:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "            else:\n",
    "                if pred_label[indx].item() > 0.5:\n",
    "                    FP += 1\n",
    "\n",
    "            total_cnt += 1\n",
    "                    \n",
    "        if TP == 0 and FP == 0:\n",
    "            FP = 1\n",
    "        if TP == 0 and FN == 0:\n",
    "            FN = 1\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        if precision == 0 and recall == 0:\n",
    "            recall = 1\n",
    "        f1 = 2*((precision*recall)/(precision+recall))\n",
    "    test_loss.append(ave_loss)\n",
    "    test_f1.append(f1)\n",
    "    print('==>>> epoch: {}, test loss: {:.6f}, acc: {:.3f}, f1:{:.3f}'.format(\n",
    "                epoch, ave_loss, correct_cnt*1.0/total_cnt, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss,label='train_loss')\n",
    "plt.plot(test_loss,label='test_loss')\n",
    "plt.plot(train_f1,label='train_f1')\n",
    "plt.plot(test_f1,label='test_f1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
