{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, train loss: 6.936235, acc: 0.025, f1:0.337\n",
      "==>>> epoch: 0, test loss: 6.715851, acc: 0.000, f1:0.212\n",
      "==>>> epoch: 1, train loss: 8.905362, acc: 0.033, f1:0.184\n",
      "==>>> epoch: 1, test loss: 8.681019, acc: 0.000, f1:0.173\n",
      "==>>> epoch: 2, train loss: 7.884067, acc: 0.033, f1:0.191\n",
      "==>>> epoch: 2, test loss: 7.671475, acc: 0.000, f1:0.190\n",
      "==>>> epoch: 3, train loss: 7.883867, acc: 0.033, f1:0.191\n",
      "==>>> epoch: 3, test loss: 7.671255, acc: 0.000, f1:0.190\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b55bd2be101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mFP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#false positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#false negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;31m#Hardcoded break after all images are loaded, due to bug in for loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m31072\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-2b55bd2be101>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mimg_as_tensor1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_img1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mimg_as_tensor2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_img2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mimg_as_tensor3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_img3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_tensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_as_tensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_as_tensor3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;31m# PIL image mode: L, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from utils import *\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "#Read training image names and labels into pandas dataframe\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "labels = df['Target'].values\n",
    "\n",
    "#Convert labels to a format MultiLabelBinarizer() can use\n",
    "#ex. \"3 5 7\" -> \"3,5,7\"\n",
    "temp = []\n",
    "for i in labels:\n",
    "    temp.append( i.replace(\" \", \",\").split(','))\n",
    "\n",
    "#Transform labels from strings to multilabel encoding\n",
    "#ex. If 7 total classes: \"3, 5, 7\" -> [0 0 1 0 1 0 1]\n",
    "trans = MultiLabelBinarizer()\n",
    "multi_labels = trans.fit_transform(temp)\n",
    "\n",
    "\n",
    "class CustomDatasetFromImages():\n",
    "    def __init__(self, path, flip, labels):\n",
    "        \n",
    "        #flip images, true or false\n",
    "        self.flip = flip\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv('train.csv', header=None)\n",
    "        # First column contains the image paths\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[1:, 0])\n",
    "        # Second column is the labels\n",
    "        self.label_arr = labels\n",
    "        self.path = path\n",
    "        \n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #Get image name from the pandas df\n",
    "        single_image_name = self.path + self.image_arr[index]\n",
    "        \n",
    "        #Load image channels\n",
    "        img_as_img1 = Image.open(single_image_name+'_blue.png')\n",
    "        img_as_img2 = Image.open(single_image_name+'_yellow.png')\n",
    "        img_as_img3 = Image.open(single_image_name+'_green.png')\n",
    "        \n",
    "        #Randomly flip images\n",
    "        tf = transforms.RandomVerticalFlip(p=1)\n",
    "        if self.flip and (random.uniform(0, 1) > 0.5):\n",
    "            img_as_img1 = tf(img_as_img1)\n",
    "            img_as_img2 = tf(img_as_img2)\n",
    "            img_as_img3 = tf(img_as_img3)\n",
    "            \n",
    "      \n",
    "        # Transform image to tensor\n",
    "        img_as_tensor1 = self.to_tensor(img_as_img1)\n",
    "        img_as_tensor2 = self.to_tensor(img_as_img2)\n",
    "        img_as_tensor3 = self.to_tensor(img_as_img3)\n",
    "        image = torch.cat((img_as_tensor1.reshape(1,512,512), img_as_tensor2.reshape(1,512,512)), dim=0)\n",
    "        image = torch.cat((image, img_as_tensor3.reshape(1,512,512)), dim=0)\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        \n",
    "        #Normalize tensor. Mean and std chosen based on pytorch transfer learning tutorial\n",
    "        tf = transforms.Normalize(mean=[0.485],std=[0.229])\n",
    "        image = tf(image)\n",
    "        \n",
    "        single_image_label = self.label_arr[index]\n",
    "\n",
    "        return (image, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "#Build data loader\n",
    "batch_size = 16\n",
    "img_dir = cwd + '/Train/'\n",
    "train = CustomDatasetFromImages(img_dir,flip=False,labels=multi_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0)\n",
    "\n",
    "#Initialize GPU settings and choose device, optimized for speed\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.fastest = True\n",
    "\n",
    "#Load pretrained model from PyTorch library\n",
    "pretrained_model = torchvision.models.resnet50(pretrained=True)\n",
    "#model_conv = models.alexnet(pretrained=True)\n",
    "#model_conv = models.squeezenet1_0(pretrained=True)\n",
    "#model_conv = models.vgg16(pretrained=True)\n",
    "#model_conv = models.densenet161(pretrained=True)\n",
    "#model_conv = models.inception_v3(pretrained=True)\n",
    "\n",
    "#Freeze all pretrained model layers, prevents updating weights during training.\n",
    "#This allows for utilization of pretrained model's ability to extract features\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#Add new fully connected layer(s) to the bottom of pretrained model, and build.\n",
    "#Weights will be updated during training, building the decision making ability of the new model.\n",
    "num_ftrs = pretrained_model.fc.in_features\n",
    "num_classes = 28\n",
    "pretrained_model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs* 100, 1024),\n",
    "            nn.Linear(1024, num_classes),\n",
    "            #nn.Dropout(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "model= pretrained_model.cuda()\n",
    "#print(model)\n",
    "\n",
    "#Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "#Sigmoid output layer and Binary Crossentropy Loss allows for multi-label predicting\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train_loss = []\n",
    "train_f1 = []\n",
    "test_loss = []\n",
    "test_f1 = []\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    test_cnt = 0\n",
    "    TP = 0 #true positive\n",
    "    FP = 0 #false positive\n",
    "    FN = 0 #false negative\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "            #Hardcoded break after all images are loaded, due to bug in for loop.\n",
    "            if (batch_idx + 1) * batch_size >= 31072:\n",
    "                break\n",
    "            #Load target labels and image batch into GPU\n",
    "            target = target.float().cuda()\n",
    "            x = x.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #Get predictions\n",
    "            out = model(x)\n",
    "            #Get loss from loss function\n",
    "            loss = criterion(out, target)\n",
    "\n",
    "            #Calculate accuracy of predictions. Only True Positives and f1 score\n",
    "            for indx in range(15):\n",
    "                acc = 0\n",
    "                for x in range(len(out[indx,:])):\n",
    "                    if target[indx,x].item() > 0.5:\n",
    "                        if out[indx,x].item() > 0.5:\n",
    "                            TP += 1\n",
    "                        else:\n",
    "                            FN += 1\n",
    "                    else:\n",
    "                        if out[indx,x].item() > 0.5:\n",
    "                            FP += 1\n",
    "            \n",
    "                    total_cnt += 1\n",
    "                    \n",
    "            ave_loss = ave_loss * 0.9 + loss.item() * 0.1\n",
    "            \n",
    "            if TP == 0 and FP == 0:\n",
    "                FP = 1\n",
    "            if TP == 0 and FN == 0:\n",
    "                FN = 1\n",
    "            precision = TP / (TP + FP)\n",
    "            recall = TP / (TP + FN)\n",
    "            f1 = 2*((precision*recall)/(precision+recall))\n",
    "            \n",
    "            if (batch_idx + 1) * 16 <= 24848:\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if (batch_idx + 1) * 16 >= 24848:\n",
    "                    train_loss.append(ave_loss)\n",
    "                    train_f1.append(f1)\n",
    "                    print('==>>> epoch: {}, train loss: {:.6f}, acc: {:.3f}, f1:{:.3f}'.format(\n",
    "                        epoch, ave_loss, TP*1.0/total_cnt, f1))\n",
    "            \n",
    "            else:\n",
    "                if test_cnt == 0:\n",
    "                    correct_cnt = 0\n",
    "                    total_cnt += 0\n",
    "                    TP = 0\n",
    "                    FP = 0\n",
    "                    FN = 0\n",
    "                    test_cnt += 1\n",
    "                if (batch_idx + 1) * 16 >= (31072 - 16):\n",
    "                    test_loss.append(ave_loss)\n",
    "                    test_f1.append(f1)\n",
    "                    print('==>>> epoch: {}, test loss: {:.6f}, acc: {:.3f}, f1:{:.3f}'.format(\n",
    "                            epoch, ave_loss, correct_cnt*1.0/total_cnt, f1))\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss,label='train_loss')\n",
    "plt.plot(test_loss,label='test_loss')\n",
    "plt.plot(train_f1,label='train_f1')\n",
    "plt.plot(test_f1,label='test_f1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
